# A unique identifier for the head node and workers of this cluster.
cluster_name: slurm-cluster

# The maximum number of workers nodes to launch in addition to the head
# node.
min_workers: 0
max_workers: 2

# The autoscaler will scale up the cluster faster with higher upscaling speed.
# E.g., if the task requires adding more nodes then autoscaler will gradually
# scale up the cluster in chunks of upscaling_speed*currently_running_nodes.
# This number should be > 0.
upscaling_speed: 1.0

# If a node is idle for this many minutes, it will be removed.
idle_timeout_minutes: 5

provider:
  type: external
  module: ray.autoscaler._private.slurm.node_provider.NodeProvider
  temp_folder_name: [_DEPLOY_RAY_PATH_]/autoscaler/slurm/temp_script/ # Need to be absolute path
  template_path: [_DEPLOY_RAY_TEMPLATE_PATH_] # Need to be absolute path
  gcs_port: "6379" # will be replaced if the port is busy
  ray_client_port: "10001" # will be replaced if the port is busy
  dashboad_port : "8265" # will be replaced if the port is busy
  k8s_namespace: "default"

# Specify the type for the ray head node (as configured below).
head_node_type: head_node

# Specify the allowed pod types for this ray cluster and the resources they provide.
available_node_types:
  head_node:
    max_workers: 0 # do not modify
    resources: {"CPU": [_DEPLOY_HEAD_CPUS_], "GPU": [_DEPLOY_HEAD_GPUS_]} # will be used by autoscaler scheduler
    node_config:
      # head_node: 1 # needed by my create node. Do not modify 
      # node_type: "SLURM"
      node_type: "BARE"

      # This fields will be filled automatically if not specified
      # head_ip: "127.0.0.1" # only useful when launching head outside slurm

      init_commands:
        - conda activate env_name # TODO:
      additional_slurm_commands: 
        - "#SBATCH --reservation=username"
        - "#SBATCH --partition=cpu"
        # - "#SBATCH -w node1"
  
  slurm_worker_node:
    # Minimum number of Ray workers of this type.
    min_workers: 0
    # Maximum number of Ray workers of this type. Takes precedence over min_workers.
    max_workers: 2

    resources: {"CPU": [_DEPLOY_WORKER_CPUS_], "GPU": [_DEPLOY_WORKER_GPUS_]} # will be used by autoscaler scheduler
    node_config: 
      head_node: 0 # needed by my create node. Do not modify 
      node_type: "SLURM"
      init_commands:
        - conda activate env_name # TODO:
      additional_slurm_commands: 
        - "#SBATCH --reservation=username"
        - "#SBATCH --partition=cpu"
  
  cloud_node_1:
    min_workers: 0
    max_workers: 1
    resources: {"CPU": 4, "GPU": 0}
    node_config:
      id: "1"
      head_node: 0
      node_type: "K8S"
      node-manager-port: 30008
      object-manager-port: 30009
      min-worker-port: 30010
      max-worker-port: 30045
  cloud_node_2:
    min_workers: 0
    max_workers: 1
    resources: {"CPU": 4, "GPU": 0}
    node_config:
      id: "2"
      head_node: 0
      node_type: "K8S"
      node-manager-port: 30048
      object-manager-port: 30049
      min-worker-port: 30050
      max-worker-port: 30085
  

# Do not modify the fields below!

# Empty setup commands for cluster launcher's checking
initialization_commands: []
setup_commands: []
head_setup_commands: []
worker_setup_commands: []
file_mounts: {}
cluster_synced_files: []

# Should be empty for Slurm provider. Fill the commands in node types instead
head_start_ray_commands: []

# Should be empty for Slurm provider. Fill the commands in node types instead
worker_start_ray_commands: []
